# Mentoria: Fundamentos de Dados para IA e Machine Learning

    A mentoria destaca que a qualidade dos dados Ã© o fator mais crÃ­tico para o sucesso de modelos de InteligÃªncia Artificial e Machine Learning. SÃ£o abordadas as principais etapas de preparaÃ§Ã£o de dados: anÃ¡lise exploratÃ³ria, limpeza, tratamento de outliers, codificaÃ§Ã£o de variÃ¡veis, normalizaÃ§Ã£o, balanceamento, seleÃ§Ã£o de atributos e validaÃ§Ã£o. Demonstra-se na prÃ¡tica o uso dessas tÃ©cnicas em um dataset de score de crÃ©dito. A mentora tambÃ©m orienta sobre competÃªncias essenciais para carreira em dados: Python, estatÃ­stica, matemÃ¡tica, entendimento de negÃ³cio e aprendizado contÃ­nuo.

O mundo aprendeu que a tecnologia Ã© um pilar essencial da sociedade e que as evoluÃ§Ãµes nÃ£o vÃ£o parar. Ã‰ necessÃ¡rio nunca parar de aprender e coaprender para que a transformaÃ§Ã£o tecnolÃ³gica aconteÃ§a. A DIO Ã© uma startup brasileira focada em transformar vidas por meio da educaÃ§Ã£o em tecnologia impulsionada por inteligÃªncia artificial, conectada a mais de 157 empresas globais, com milhÃµes de bolsas distribuÃ­das e impacto em milhÃµes de pessoas.

A DIO jÃ¡ foi premiada como Tech Pioneers 2023 pelo World Economic Forum e atua globalmente conectando profissionais Ã s empresas mais inovadoras do mundo. Sua missÃ£o Ã© impulsionar a transformaÃ§Ã£o tecnolÃ³gica e o desenvolvimento de talentos.

Na sequÃªncia, inicia-se a mentoria sobre Fundamentos de Dados para InteligÃªncia Artificial e Machine Learning. A convidada Ã© Evelyn, arquiteta de soluÃ§Ãµes na AWS, com forte experiÃªncia em dados, analytics e machine learning. Ela destaca que a mentoria terÃ¡ carÃ¡ter introdutÃ³rio, mas com base prÃ¡tica, incluindo demonstraÃ§Ã£o em Jupyter Notebook.

Evelyn explica que muitos projetos focam excessivamente nos modelos e esquecem da qualidade dos dados. Dados mal tratados geram ruÃ­do, viÃ©s e inconsistÃªncia, e nenhum algoritmo sofisticado consegue compensar dados ruins. Modelos aprendem padrÃµes a partir dos dados e podem amplificar erros existentes.

A preparaÃ§Ã£o de dados comeÃ§a com a anÃ¡lise exploratÃ³ria, que permite entender variÃ¡veis, distribuiÃ§Ãµes e possÃ­veis problemas. Em seguida ocorre a limpeza dos dados, tratando valores invÃ¡lidos, tipos incorretos e inconsistÃªncias. TambÃ©m Ã© necessÃ¡rio tratar valores ausentes (missing values), pois imputaÃ§Ãµes inadequadas podem distorcer o modelo.

O tratamento de outliers Ã© abordado por meio de tÃ©cnicas como Z-score, intervalo interquartil (IQR), boxplot e winsorizaÃ§Ã£o. TransformaÃ§Ãµes matemÃ¡ticas e estatÃ­sticas, como uso de logaritmos, ajudam a reduzir efeitos de distribuiÃ§Ãµes extremas.

VariÃ¡veis categÃ³ricas precisam ser transformadas em valores numÃ©ricos. TÃ©cnicas incluem one-hot encoding, label encoding e target encoding. A escolha depende da cardinalidade e do impacto no modelo. Label encoding pode induzir relaÃ§Ã£o ordinal indevida entre categorias.

A normalizaÃ§Ã£o e padronizaÃ§Ã£o sÃ£o utilizadas para manter as variÃ¡veis em escalas adequadas. Alguns mÃ©todos sÃ£o sensÃ­veis a outliers e exigem cuidado na escolha.

Na etapa de amostragem, os dados sÃ£o divididos em conjuntos de treino e teste. O mÃ©todo holdout Ã© comum, mas a validaÃ§Ã£o cruzada (cross validation) melhora a estimativa do desempenho. Em problemas com classes desbalanceadas, a estratificaÃ§Ã£o e tÃ©cnicas como SMOTE ajudam a manter representatividade.

A seleÃ§Ã£o de atributos envolve anÃ¡lise de correlaÃ§Ã£o, testes estatÃ­sticos (como qui-quadrado para variÃ¡veis categÃ³ricas) e anÃ¡lise de importÃ¢ncia de features. Deve-se evitar colinearidade, que aumenta a variÃ¢ncia do modelo. MÃ©tricas como VIF ajudam a detectar esse problema.

Outro cuidado Ã© evitar data leakage, quando uma variÃ¡vel indevidamente antecipa o resultado. TÃ©cnicas como Lasso e SHAP auxiliam na avaliaÃ§Ã£o da relevÃ¢ncia das variÃ¡veis.

Evelyn tambÃ©m aborda tÃ©cnicas de melhoria de modelos jÃ¡ treinados, como fine-tuning (especializaÃ§Ã£o com novos dados) e destilaÃ§Ã£o (transferÃªncia de conhecimento de um modelo maior para um menor).

Na demonstraÃ§Ã£o prÃ¡tica, utiliza-se um dataset de classificaÃ§Ã£o de score de crÃ©dito obtido do Kaggle. SÃ£o realizadas etapas de anÃ¡lise exploratÃ³ria, balanceamento de classes, tratamento de outliers, codificaÃ§Ã£o de variÃ¡veis categÃ³ricas, seleÃ§Ã£o de atributos e divisÃ£o dos dados para treino e teste usando cross validation.

A mentoria finaliza com orientaÃ§Ãµes de carreira. Para atuar na Ã¡rea de dados e machine learning, recomenda-se conhecimento em Python, matemÃ¡tica, estatÃ­stica, entendimento de negÃ³cio e fundamentos de engenharia de dados. TransiÃ§Ã£o de carreira exige dedicaÃ§Ã£o e estudo contÃ­nuo.

---
### AnotaÃ§Ãµes de Estudo
# Fundamentos de Dados para IA e Machine Learning

## ğŸ¯ Objetivo
Garantir qualidade dos dados para maximizar desempenho, confiabilidade e generalizaÃ§Ã£o dos modelos de Machine Learning.

---

## âš ï¸ Problemas de Dados Mal Tratados
- RuÃ­do
- ViÃ©s
- InconsistÃªncia
- AmplificaÃ§Ã£o de erros pelo modelo
- Algoritmos avanÃ§ados nÃ£o compensam dados ruins

---

## ğŸ” Etapas da PreparaÃ§Ã£o de Dados

### 1. AnÃ¡lise ExploratÃ³ria (EDA)
- Entender variÃ¡veis e distribuiÃ§Ãµes
- Identificar valores extremos, nulos e padrÃµes
- VisualizaÃ§Ãµes: histogramas, boxplot, correlaÃ§Ã£o

---

### 2. Limpeza de Dados
- Tipos incorretos (string em campo numÃ©rico)
- Valores invÃ¡lidos (ex: negativos indevidos)
- RemoÃ§Ã£o ou correÃ§Ã£o de inconsistÃªncias

---

### 3. Tratamento de Missing Values
- ImputaÃ§Ã£o (mÃ©dia, mediana, etc.)
- RemoÃ§Ã£o de linhas/colunas
- Avaliar impacto no modelo

---

### 4. Tratamento de Outliers
**TÃ©cnicas:**
- Z-score
- IQR (Q3 âˆ’ Q1)
- Boxplot
- WinsorizaÃ§Ã£o
- Percentis

**Objetivo:**
- Evitar distorÃ§Ã£o do modelo
- Reduzir influÃªncia de extremos

---

### 5. TransformaÃ§Ãµes MatemÃ¡ticas
- Logaritmo
- Escalonamento
- ReduÃ§Ã£o de assimetria
- EstabilizaÃ§Ã£o de variÃ¢ncia

---

### 6. CodificaÃ§Ã£o de VariÃ¡veis CategÃ³ricas
- One-Hot Encoding
- Label Encoding
- Target Encoding

**Cuidados:**
- Alta cardinalidade gera muitas colunas
- Label encoding pode gerar falsa ordem
- Avaliar impacto computacional

---

### 7. NormalizaÃ§Ã£o e PadronizaÃ§Ã£o
- NormalizaÃ§Ã£o (0 a 1)
- StandardScaler (mÃ©dia 0, desvio 1)
- RobustScaler (menos sensÃ­vel a outliers)

---

### 8. Amostragem e ValidaÃ§Ã£o
- Holdout: 70â€“80% treino / 20â€“30% teste
- Cross Validation (K-Fold)
- EstratificaÃ§Ã£o para classes desbalanceadas
- SMOTE para balanceamento

---

### 9. AvaliaÃ§Ã£o de Erro
- Erro = ViÃ©s + VariÃ¢ncia + RuÃ­do
- Underfitting â†’ alto viÃ©s
- Overfitting â†’ alta variÃ¢ncia
- Buscar equilÃ­brio

---

### 10. SeleÃ§Ã£o de Atributos (Feature Selection)
**MÃ©todos:**
- CorrelaÃ§Ã£o
- Qui-quadrado
- Lasso
- SHAP
- Feature importance

**Cuidados:**
- Colinearidade
- VIF > 5 indica alerta
- Evitar data leakage
- NÃ£o usar apenas correlaÃ§Ã£o linear

---

### 11. Melhoria de Modelos
- Fine-tuning â†’ especializaÃ§Ã£o com novos dados
- DestilaÃ§Ã£o â†’ transferÃªncia de conhecimento
- Fine-tuning reduz viÃ©s
- DestilaÃ§Ã£o reduz variÃ¢ncia

---

## ğŸ§ª DemonstraÃ§Ã£o PrÃ¡tica
- Dataset: Credit Score (Kaggle)
- Ferramentas:
  - Pandas
  - NumPy
  - Matplotlib
  - Scikit-learn
  - SageMaker
- Pipeline:
  1. EDA
  2. Limpeza
  3. Balanceamento
  4. Encoding
  5. Feature Selection
  6. Split e Cross Validation

---

## ğŸ‘¨â€ğŸ’» CompetÃªncias para a Ãrea
- Python
- EstatÃ­stica (inferÃªncia, probabilidade)
- MatemÃ¡tica
- Engenharia de dados (Spark, pipelines)
- Entendimento de negÃ³cio
- Aprendizado contÃ­nuo
